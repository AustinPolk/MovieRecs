{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "def retrieve_movie_list():\n",
    "    movies = []\n",
    "    with open(\"movie_titles.txt\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            title = line.strip()\n",
    "            movies.append(title)\n",
    "    return movies\n",
    "\n",
    "def get_movie_plot(movie_name: str) -> str:\n",
    "    plotPath = fr\"Wikipedia Plots/{movie_name}.txt\"\n",
    "    plot = \"\"\n",
    "    with open(plotPath, encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.isspace():\n",
    "                continue\n",
    "            plot += line.strip()\n",
    "    return plot\n",
    "\n",
    "def get_movie_reviews(movie_name: str) -> str:\n",
    "    reviewsPath = fr\"IMDB Reviews/{movie_name}.txt\"\n",
    "    reviews = \"\"\n",
    "    with open(reviewsPath, encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.isspace():\n",
    "                continue\n",
    "            reviews += line.strip()\n",
    "    return reviews\n",
    "\n",
    "def get_significant_word_counts(words: str, desired_pos: list[str]) -> dict[str, int]:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(words)\n",
    "\n",
    "    token_counts = {}\n",
    "\n",
    "    for token in doc:\n",
    "        \n",
    "        if token.pos_ not in desired_pos:\n",
    "            continue\n",
    "\n",
    "        t = token.lemma_\n",
    "        if t not in token_counts:\n",
    "            token_counts[t] = 0\n",
    "        token_counts[t] += 1\n",
    "\n",
    "    return token_counts\n",
    "\n",
    "def get_plot_vector(movie, desired_pos, wv):\n",
    "    total = np.zeros(300, dtype=float)\n",
    "\n",
    "    plot = get_movie_plot(movie)\n",
    "    word_counts = get_significant_word_counts(plot, desired_pos)\n",
    "\n",
    "    for word, count in word_counts.items():\n",
    "        try:\n",
    "            this_embedding = wv[word]\n",
    "        except:\n",
    "            continue\n",
    "        weighted = count * this_embedding\n",
    "        total += weighted\n",
    "\n",
    "    magnitude = np.linalg.norm(total)\n",
    "    normalized = total / magnitude\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def get_reviews_vector(movie, desired_pos, wv):\n",
    "    total = np.zeros(300, dtype=float)\n",
    "\n",
    "    reviews = get_movie_reviews(movie)\n",
    "    word_counts = get_significant_word_counts(reviews, desired_pos)\n",
    "\n",
    "    for word, count in word_counts.items():\n",
    "        try:\n",
    "            this_embedding = wv[word]\n",
    "        except:\n",
    "            continue\n",
    "        weighted = count * this_embedding\n",
    "        total += weighted\n",
    "\n",
    "    magnitude = np.linalg.norm(total)\n",
    "    normalized = total / magnitude\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def cosine_similarity(A, B):\n",
    "    # Calculate dot product\n",
    "    dot_product = sum(a*b for a, b in zip(A, B))\n",
    "\n",
    "    # Calculate the magnitude of each vector\n",
    "    magnitude_A = sum(a*a for a in A)**0.5\n",
    "    magnitude_B = sum(b*b for b in B)**0.5\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_similarity = dot_product / (magnitude_A * magnitude_B)\n",
    "    return cosine_similarity\n",
    "\n",
    "def normalized_cosine_similarity(A, B):\n",
    "    # Calculate dot product\n",
    "    dot_product = sum(a*b for a, b in zip(A, B))\n",
    "\n",
    "    # Calculate the magnitude of each vector\n",
    "    #magnitude_A = sum(a*a for a in A)**0.5\n",
    "    #magnitude_B = sum(b*b for b in B)**0.5\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_similarity = dot_product# / (magnitude_A * magnitude_B)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "try:\n",
    "    wv\n",
    "except:\n",
    "    print(\"loading word embeddings\")\n",
    "    wv = api.load('word2vec-google-news-300')\n",
    "finally:\n",
    "    print(\"word embeddings loaded\")\n",
    "\n",
    "plot_pos = [\"NOUN\", \"VERB\"]     # capture the action of the plot\n",
    "reviews_pos = [\"ADJ\", \"ADV\"]    # capture the description of the movie\n",
    "\n",
    "movie_list = retrieve_movie_list()\n",
    "movie_plot_vectors = {}\n",
    "movie_reviews_vectors = {}\n",
    "for movie in movie_list:\n",
    "    print(movie)\n",
    "    movie_plot_vectors[movie] = get_plot_vector(movie, plot_pos, wv)\n",
    "    movie_reviews_vectors[movie] = get_reviews_vector(movie, reviews_pos, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity_min = 0.7\n",
    "plot_similarity_scaling = 1 / (1 - plot_similarity_min)\n",
    "reviews_similarity_min = 0.85\n",
    "reviews_similarity_scaling = 1 / (1 - reviews_similarity_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarities = {}\n",
    "\n",
    "for a_movie in movie_list:\n",
    "    if a_movie not in plot_similarities:\n",
    "        plot_similarities[a_movie] = {}\n",
    "\n",
    "    for b_movie in movie_list:\n",
    "        A = movie_plot_vectors[a_movie]\n",
    "        B = movie_plot_vectors[b_movie]\n",
    "        s = normalized_cosine_similarity(A, B)\n",
    "        s -= plot_similarity_min\n",
    "        s *= plot_similarity_scaling\n",
    "        print(f\"P: {a_movie} vs. {b_movie} -> {s}\")\n",
    "        plot_similarities[a_movie][b_movie] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_similarities = {}\n",
    "\n",
    "for a_movie in movie_list:\n",
    "    if a_movie not in reviews_similarities:\n",
    "        reviews_similarities[a_movie] = {}\n",
    "\n",
    "    for b_movie in movie_list:\n",
    "        A = movie_reviews_vectors[a_movie]\n",
    "        B = movie_reviews_vectors[b_movie]\n",
    "        s = normalized_cosine_similarity(A, B)\n",
    "        s -= reviews_similarity_min\n",
    "        s *= reviews_similarity_scaling\n",
    "        print(f\"R: {a_movie} vs. {b_movie} -> {s}\")\n",
    "        reviews_similarities[a_movie][b_movie] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotten tomatoes critic, rotten tomatoes user, imdb user\n",
    "movie_ratings = {\"Avatar\": [81, 82, 7.9],\n",
    "    \"BlinkTwice\": [74, 70, 6.5],\n",
    "    \"ChildrenOfMen\": [92, 85, 7.9],\n",
    "    \"CitizenKane\": [99, 90, 8.3],\n",
    "    \"DjangoUnchained\": [87, 92, 8.5],\n",
    "    \"GetOut\": [98, 86, 7.8],\n",
    "    \"Inception\": [87, 91, 8.8],\n",
    "    \"KnivesOut\": [97, 92, 7.9],\n",
    "    \"Mandy\": [90, 67, 6.5],\n",
    "    \"Parasite\": [99, 90, 8.5],\n",
    "    \"SnowPiercer\": [94, 72, 7.1],\n",
    "    \"TheGreatestShowman\": [57, 86, 7.5],\n",
    "    \"TheMartian\": [91, 91, 8.0],\n",
    "    \"TheMummy\": [62, 75, 7.1],\n",
    "    \"TheRevenant\": [78, 84, 8.0],\n",
    "    \"TheRitual\": [74, 63, 6.3],\n",
    "    \"Lord of the Rings\\\\FellowshipOfTheRing\": [92, 95, 8.9],\n",
    "    \"Lord of the Rings\\\\ReturnOfTheKing\": [94, 86, 9.0],\n",
    "    \"Lord of the Rings\\\\TheTwoTowers\": [95, 95, 8.8],\n",
    "    \"Pirates of the Caribbean\\\\AtWorldsEnd\": [44, 72, 7.1],\n",
    "    \"Pirates of the Caribbean\\\\CurseOfTheBlackPearl\": [80, 86, 8.1],\n",
    "    \"Pirates of the Caribbean\\\\DeadMansChest\": [53, 72, 7.4],\n",
    "    \"Pirates of the Caribbean\\\\DeadMenTellNoTales\": [30, 60, 6.5],\n",
    "    \"Pirates of the Caribbean\\\\OnStrangerTides\": [33, 54, 6.6],\n",
    "    \"Star Wars\\\\StarWarsANewHope\": [93, 96, 8.6],\n",
    "    \"Star Wars\\\\StarWarsEmpireStrikesBack\": [95, 97, 8.7],\n",
    "    \"Star Wars\\\\StarWarsReturnOfTheJedi\": [82, 94, 8.3],\n",
    "    \"The Godfather\\\\GodfatherPart1\": [97, 98, 9.2],\n",
    "    \"The Godfather\\\\GodfatherPart2\": [96, 97, 9.0],\n",
    "    \"The Godfather\\\\GodfatherPart3\": [66, 68, 7.6],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = {}\n",
    "\n",
    "user_weight = 0.9\n",
    "critic_weight = 1 - user_weight\n",
    "\n",
    "for movie in movie_list:\n",
    "    scores = movie_ratings[movie]\n",
    "    rot_tom_critics = float(scores[0])/100\n",
    "    rot_tom_audience = float(scores[1])/100\n",
    "    imdb_users = float(scores[2]) / 10\n",
    "    \n",
    "    user_rating = (rot_tom_audience + imdb_users) / 2\n",
    "    overall = user_rating * user_weight + rot_tom_critics * critic_weight\n",
    "    \n",
    "    ratings[movie] = overall\n",
    "    print(f\"{movie} -> {overall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = {}\n",
    "\n",
    "# in this case, think of a as the unknown movie, and b as the known movie\n",
    "for a_movie in movie_list:\n",
    "    if a_movie not in sentiment_scores:\n",
    "        sentiment_scores[a_movie] = {}\n",
    "\n",
    "    for b_movie in movie_list:\n",
    "        a_rating = ratings[a_movie]\n",
    "        b_rating = ratings[b_movie]\n",
    "        delta = b_rating - a_rating\n",
    "        \n",
    "        r_similarity = reviews_similarities[a_movie][b_movie]\n",
    "        score = (1.1 + delta) * r_similarity # increases the similarity if reviews for a are better than b, with a slight upward bias, otherwise reduces it\n",
    "        \n",
    "        print(f\"{a_movie} vs. {b_movie} -> {score}\")\n",
    "        sentiment_scores[a_movie][b_movie] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_points = []\n",
    "y_points = []\n",
    "\n",
    "for a_movie in movie_list:\n",
    "    for b_movie in movie_list:\n",
    "        if a_movie is b_movie:\n",
    "            continue\n",
    "        p = plot_similarities[a_movie][b_movie]\n",
    "        #r = reviews_similarities[a_movie][b_movie]\n",
    "        r = sentiment_scores[a_movie][b_movie]\n",
    "        x_points.append(p)\n",
    "        y_points.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(x_points, y_points)\n",
    "plt.xlabel(\"Plot similarity\")\n",
    "plt.ylabel(\"Sentiment score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I need to make some function Z to take plot similarity and sentiment score and compute a probability that you will like a movie\n",
    "# for an unknown movie a, and a known liked movie b, with p and s as the scores, what is the probability that you will like a, given that you like b?\n",
    "# then, what is the probability that you will like a, maybe I can use the sum of the conditional probabilities?\n",
    "import math\n",
    "\n",
    "p_weight = 1\n",
    "r_weight = 0.5\n",
    "neg_bias = 0\n",
    "\n",
    "# sigmoid function parameters\n",
    "a = 6\n",
    "b = 0.5\n",
    "sigmoid = lambda x: 1 / (1 + math.exp(-a*(x-b)))\n",
    "\n",
    "z = lambda p, r: p_weight * p + r_weight * r - neg_bias\n",
    "Z = lambda p, r: sigmoid(z(p, r)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = {}\n",
    "\n",
    "for a_movie in movie_list:\n",
    "    if a_movie not in probabilities:\n",
    "        probabilities[a_movie] = {}\n",
    "    for b_movie in movie_list:\n",
    "        if a_movie is b_movie:\n",
    "            probabilities[a_movie][b_movie] = 1.0\n",
    "        p = plot_similarities[a_movie][b_movie]\n",
    "        #r = reviews_similarities[a_movie][b_movie]\n",
    "        r = sentiment_scores[a_movie][b_movie]\n",
    "        final = Z(p, r)\n",
    "        probabilities[a_movie][b_movie] = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_count = len(movie_list)\n",
    "matrix = np.zeros((movie_count, movie_count))\n",
    "\n",
    "i = 0\n",
    "for a_movie in movie_list:\n",
    "    j = 0\n",
    "    for b_movie in movie_list:\n",
    "        prob = probabilities[a_movie][b_movie]\n",
    "        matrix[i, j] = prob\n",
    "        j += 1\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(a, b, pw, rw, neg):\n",
    "    # sigmoid function parameters\n",
    "    #a = 6\n",
    "    #b = 0.5\n",
    "    sigmoid = lambda x: 1 / (1 + math.exp(-a*(x-b)))\n",
    "\n",
    "    z = lambda p, r: p_weight * p + r_weight * r - neg_bias\n",
    "    Z = lambda p, r: sigmoid(z(p, r)) \n",
    "\n",
    "    probabilities = {}\n",
    "\n",
    "    for a_movie in movie_list:\n",
    "        if a_movie not in probabilities:\n",
    "            probabilities[a_movie] = {}\n",
    "        for b_movie in movie_list:\n",
    "            if a_movie is b_movie:\n",
    "                probabilities[a_movie][b_movie] = 1.0\n",
    "            p = plot_similarities[a_movie][b_movie]\n",
    "            #r = reviews_similarities[a_movie][b_movie]\n",
    "            r = sentiment_scores[a_movie][b_movie]\n",
    "            final = Z(p, r)\n",
    "            probabilities[a_movie][b_movie] = final\n",
    "\n",
    "    movie_count = len(movie_list)\n",
    "    matrix = np.zeros((movie_count, movie_count))\n",
    "\n",
    "    i = 0\n",
    "    for a_movie in movie_list:\n",
    "        j = 0\n",
    "        for b_movie in movie_list:\n",
    "            prob = probabilities[a_movie][b_movie]\n",
    "            matrix[i, j] = prob\n",
    "            j += 1\n",
    "        i += 1\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these parameters, except maybe a and b, need to be trained for accuracy based on real data\n",
    "matrix = get_matrix(a=6, b=0.5, pw=0.7, rw=0.3, neg=0.5)\n",
    "plt.imshow(matrix) \n",
    "  \n",
    "plt.title(\"Heat Map\") \n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(I like Avatar | I like BlinkTwice) = 0.48575887530781126\n"
     ]
    }
   ],
   "source": [
    "a = \"Avatar\"\n",
    "b = \"BlinkTwice\"\n",
    "a_i = movie_list.index(a)\n",
    "b_i = movie_list.index(b)\n",
    "\n",
    "print(f\"P(I like {a} | I like {b}) = {matrix[a_i, b_i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(I like Avatar | I like BlinkTwice and I like TheMartian) = 0.6084645983603445\n"
     ]
    }
   ],
   "source": [
    "a = \"Avatar\"\n",
    "b = \"BlinkTwice\"\n",
    "c = \"TheMartian\"\n",
    "a_i = movie_list.index(a)\n",
    "b_i = movie_list.index(b)\n",
    "c_i = movie_list.index(c)\n",
    "\n",
    "print(f\"P(I like {a} | I like {b} and I like {c}) = {0.66 * matrix[a_i, b_i] + 0.33 * matrix[a_i, c_i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5454545454545455, 0.27272727272727276, 0.18181818181818182]\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "\n",
    "initial = [1 / x for x in range(1, 1 + n)]\n",
    "total = sum(initial)\n",
    "weights = [x / total for x in initial]\n",
    "\n",
    "print(weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
